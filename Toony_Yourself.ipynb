{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWUndhVgtePK/GdEF/VOhM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GAN/blob/master/Toony_Yourself.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Toony Yourself**\n",
        "\n",
        "implementation: http://cedro3.com/ai/toonify-yourself/#comment-869\n",
        "\n",
        "original: "
      ],
      "metadata": {
        "id": "dfb-8Mp_vZVU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrUdKnhCs5P-",
        "outputId": "95ade470-61fb-453e-ebd7-b3d7c103825f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Total 269 (delta 0), reused 0 (delta 0), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (269/269), 2.32 MiB | 12.30 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n",
            "/content/stylegan2\n",
            "CPU says hello.\n",
            "GPU says hello.\n"
          ]
        }
      ],
      "source": [
        "#StyleGANをGit clone\n",
        "%tensorflow_version 1.x\n",
        "!git clone https://github.com/justinpinkney/stylegan2\n",
        "\n",
        "%cd stylegan2\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        " \n",
        "# フォルダーの作成\n",
        "!mkdir aligned\n",
        "!mkdir generated"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ffhqモデル(Baseモデル)とblendedモデルのダウンロード\n",
        "#import pretrained_networks\n",
        "import gdown\n",
        "\n",
        " \n",
        "# use my copy of the blended model to save Doron's download bandwidth\n",
        "# get the original here https://mega.nz/folder/OtllzJwa#C947mCCdEfMCRTWnDcs4qw\n",
        "#blended_url = \"https://drive.google.com/uc?id=1H73TfV5gQ9ot7slSed_l-lim9X7pMRiU\"\n",
        "blended_url = \"https://drive.google.com/uc?id=1BRqqHWk_4BjNHLXTrpHkoxmZhGw3CU59\" \n",
        "ffhq_url = \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "#エラーがでてうまくいかないので、ダイレクトにダウンロードすることにする \n",
        "#_, _, Gs_blended = pretrained_networks.load_networks(blended_url)\n",
        "#_, _, Gs = pretrained_networks.load_networks(ffhq_url)\n",
        "gdown.download(blended_url, quiet=False)\n",
        "gdown.download(ffhq_url, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "LaHIEZSItJe-",
        "outputId": "00a7f2dd-408a-49f6-a756-af7421005a18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BRqqHWk_4BjNHLXTrpHkoxmZhGw3CU59\n",
            "To: /content/stylegan2/ffhq-cartoon-blended-64.pkl\n",
            "100%|██████████| 382M/382M [00:01<00:00, 230MB/s]\n",
            "Downloading...\n",
            "From: http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\n",
            "To: /content/stylegan2/stylegan2-ffhq-config-f.pkl\n",
            "100%|██████████| 382M/382M [00:01<00:00, 346MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stylegan2-ffhq-config-f.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**必要な関数を定義**"
      ],
      "metadata": {
        "id": "FdKJO8GavUwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像表示\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(30, 40))\n",
        "    files = glob.glob(folder)\n",
        "    files.sort()\n",
        "    images=[]\n",
        "    for i in range(len(files)):\n",
        "        img = Image.open(files[i])    \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(str(i), fontsize=20)               \n",
        "    plt.show()\n",
        "    plt.close()  \n",
        "\n",
        "# 潜在変数(latents)から生成した画像を表示\n",
        "import PIL.Image\n",
        "def display(latents):\n",
        "    \n",
        "    synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "  \n",
        "    fig = plt.figure(figsize=(30, 40))   \n",
        "    for i in range(len(latents)):\n",
        "        vec = latents[i].reshape(1,18,512)\n",
        "        images =  Gs_blended.components.synthesis.run(vec, randomize_noise=False, **synthesis_kwargs)  \n",
        "        images = images.transpose((0,2,3,1))     \n",
        "        PIL.Image.fromarray(images[0], 'RGB')   \n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images[0])\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(str(i), fontsize=20)               \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# 潜在変数(latents)の順番を指定して、トランジションのGIFを作成する\n",
        "import os\n",
        "\n",
        "def generate_gif(latents, idx):\n",
        "\n",
        "    synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "\n",
        "    image_gif = []\n",
        "    os.makedirs('my/gif', exist_ok=True)\n",
        "    for j in range(len(idx)-1):\n",
        "        for i in range(20):\n",
        "            latent = latents[idx[j]]+(latents[idx[j+1]]-latents[idx[j]])*i/19\n",
        "            latent = latent.reshape(1, 18, 512)\n",
        "            images =  Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs) \n",
        "            images = images.transpose((0,2,3,1)) \n",
        "            image_one = PIL.Image.fromarray(images[0], 'RGB')\n",
        "            image_gif.append(image_one.resize((256,256))) \n",
        "\n",
        "    image_gif[0].save('./my/gif/anime.gif', save_all=True, append_images=image_gif[1:],\n",
        "                      duration=100, loop=0) "
      ],
      "metadata": {
        "id": "qe2XL4y3vTl6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# サンプル写真のダウンロードと整形\n",
        "import os \n",
        "import bz2\n",
        "import shutil\n",
        "import requests\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "# rawフォルダを作成\n",
        "try: \n",
        "    shutil.rmtree(\"/content/stylegan2/raw\")\n",
        "    print(\"directory deleted\")\n",
        "    print(\"\")\n",
        "except:\n",
        "    pass\n",
        "os.makedirs(\"/content/stylegan2/raw\", exist_ok=True)\n",
        "\n",
        "\n",
        "#Webから画像をダウンロードしてrawフォルダに格納\n",
        "url = \"https://images.unsplash.com/photo-1597223557154-721c1cecc4b0?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxzZWFyY2h8Mnx8aHVtYW4lMjBmYWNlfGVufDB8fDB8fA%3D%3D&w=1000&q=80\"\n",
        "file_name = \"/content/stylegan2/raw/sample.jpg\"\n",
        "\n",
        "response = requests.get(url)\n",
        "image = response.content\n",
        "with open(file_name, \"wb\") as aaa:\n",
        "    aaa.write(image)\n",
        "\n",
        "\"\"\"\n",
        "#dlibのshape_predictor_5_face_landmarks.datをダウンロード\n",
        "url='http://dlib.net/files/shape_predictor_5_face_landmarks.dat.bz2'\n",
        "save_name='shape_predictor_5_face_landmarks.dat.bz2'\n",
        "urllib.request.urlretrieve(url, save_name)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "wrgcSkltyGEm",
        "outputId": "71ede185-c4fb-408a-8a29-485a0f11c552"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#dlibのshape_predictor_5_face_landmarks.datをダウンロード\\nurl='http://dlib.net/files/shape_predictor_5_face_landmarks.dat.bz2'\\nsave_name='shape_predictor_5_face_landmarks.dat.bz2'\\nurllib.request.urlretrieve(url, save_name)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "# For static images:\n",
        "IMAGE_FILES = ['/content/stylegan2/raw/sample.jpg']\n",
        "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
        "with mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5) as face_mesh:\n",
        "  for idx, file in enumerate(IMAGE_FILES):\n",
        "    image = cv2.imread(file)\n",
        "    # Convert the BGR image to RGB before processing.\n",
        "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Print and draw face mesh landmarks on the image.\n",
        "    if not results.multi_face_landmarks:\n",
        "      continue\n",
        "    annotated_image = image.copy()\n",
        "    for face_landmarks in results.multi_face_landmarks:\n",
        "      #print('face_landmarks:', face_landmarks)\n",
        "      \n",
        "      mp_drawing.draw_landmarks(\n",
        "          image=annotated_image,\n",
        "          landmark_list=face_landmarks,\n",
        "          connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "          landmark_drawing_spec=None,\n",
        "          connection_drawing_spec=mp_drawing_styles\n",
        "          .get_default_face_mesh_tesselation_style())\n",
        "      # mp_drawing.draw_landmarks(\n",
        "      #     image=annotated_image,\n",
        "      #     landmark_list=face_landmarks,\n",
        "      #     connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "      #     landmark_drawing_spec=None,\n",
        "      #     connection_drawing_spec=mp_drawing_styles\n",
        "      #     .get_default_face_mesh_contours_style())\n",
        "      # mp_drawing.draw_landmarks(\n",
        "      #     image=annotated_image,\n",
        "      #     landmark_list=face_landmarks,\n",
        "      #     connections=mp_face_mesh.FACEMESH_IRISES,\n",
        "      #     landmark_drawing_spec=None,\n",
        "      #     connection_drawing_spec=mp_drawing_styles\n",
        "      #     .get_default_face_mesh_iris_connections_style())\n",
        "    cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)\n",
        "    \n",
        "cv2_imshow(annotated_image)"
      ],
      "metadata": {
        "id": "JCXGybRYuXLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(file)\n",
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvQIeSkp3mvr",
        "outputId": "ea66204f-1554-43d4-9563-4f6e7b737549"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 1000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "landmarks = results.multi_face_landmarks[0]"
      ],
      "metadata": {
        "id": "49yJgaqt2qEk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "landmarks.landmark[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-KW6Ju22qav",
        "outputId": "69880246-fc4c-480b-9247-941a2a9bcc41"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "x: 0.5013298392295837\n",
              "y: 0.729648768901825\n",
              "z: -0.05366979166865349"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UG0AQdiq3Zpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import dlib\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_5_face_landmarks.dat')\n",
        "\n",
        "img = url\n",
        "\n",
        "def shape_to_normal(shape):\n",
        "    shape_normal = []\n",
        "    for i in range(0, 5):\n",
        "        shape_normal.append((i, (shape.part(i).x, shape.part(i).y)))\n",
        "    return shape_normal\n",
        "def get_eyes_nose_dlib(shape):\n",
        "    nose = shape[4][1]\n",
        "    left_eye_x = int(shape[3][1][0] + shape[2][1][0]) // 2\n",
        "    left_eye_y = int(shape[3][1][1] + shape[2][1][1]) // 2\n",
        "    right_eyes_x = int(shape[1][1][0] + shape[0][1][0]) // 2\n",
        "    right_eyes_y = int(shape[1][1][1] + shape[0][1][1]) // 2\n",
        "    return nose, (left_eye_x, left_eye_y), (right_eyes_x, right_eyes_y)\n",
        "\n",
        "def distance(a, b):\n",
        "    return np.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)\n",
        "\n",
        "def cosine_formula(length_line1, length_line2, length_line3):\n",
        "    cos_a = -(length_line3 ** 2 - length_line2 ** 2 - length_line1 ** 2) / (2 * length_line2 * length_line1)\n",
        "    return cos_a\n",
        "\n",
        "def rotate_point(origin, point, angle):\n",
        "    ox, oy = origin\n",
        "    px, py = point\n",
        "\n",
        "    qx = ox + np.cos(angle) * (px - ox) - np.sin(angle) * (py - oy)\n",
        "    qy = oy + np.sin(angle) * (px - ox) + np.cos(angle) * (py - oy)\n",
        "    return qx, qy\n",
        "\n",
        "\n",
        "def is_between(point1, point2, point3, extra_point):\n",
        "    c1 = (point2[0] - point1[0]) * (extra_point[1] - point1[1]) - (point2[1] - point1[1]) * (extra_point[0] - point1[0])\n",
        "    c2 = (point3[0] - point2[0]) * (extra_point[1] - point2[1]) - (point3[1] - point2[1]) * (extra_point[0] - point2[0])\n",
        "    c3 = (point1[0] - point3[0]) * (extra_point[1] - point3[1]) - (point1[1] - point3[1]) * (extra_point[0] - point3[0])\n",
        "    if (c1 < 0 and c2 < 0 and c3 < 0) or (c1 > 0 and c2 > 0 and c3 > 0):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "rects = detector(gray, 0)\n",
        "if len(rects) > 0:\n",
        "    for rect in rects:\n",
        "        x = rect.left()\n",
        "        y = rect.top()\n",
        "        w = rect.right()\n",
        "        h = rect.bottom()\n",
        "        shape = predictor(gray, rect)\n",
        "\n",
        "#obtain central coordinates of nose and eyes\n",
        "shape = shape_to_normal(shape)\n",
        "nose, left_eye, right_eye = get_eyes_nose_dlib(shape)\n",
        "center_of_forehead = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
        "center_pred = (int((x + w) / 2), int((y + y) / 2))\n",
        "\n",
        "length_line1 = distance(center_of_forehead, nose)\n",
        "length_line2 = distance(center_pred, nose)\n",
        "length_line3 = distance(center_pred, center_of_forehead)\n",
        "\n",
        "cos_a = cosine_formula(length_line1, length_line2, length_line3)\n",
        "angle = np.arccos(cos_a)\n",
        "\n",
        "rotated_point = rotate_point(nose, center_of_forehead, angle)\n",
        "rotated_point = (int(rotated_point[0]), int(rotated_point[1]))\n",
        "if is_between(nose, center_of_forehead, center_pred, rotated_point):\n",
        "    angle = np.degrees(-angle)\n",
        "else:\n",
        "    angle = np.degrees(angle)\n",
        "\n",
        "img = Image.fromarray(img)\n",
        "img = np.array(img.rotate(angle))\n"
      ],
      "metadata": {
        "id": "fSjXu82gzyHl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "2b5aa5cc-57d4-4bb0-d808-5f59570dbea4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f2def5d5dd83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shape_predictor_5_face_landmarks.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unable to open shape_predictor_5_face_landmarks.dat"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 顔画像の切り取り\n",
        "!python align_images.py raw aligned\n",
        "display_pic('./aligned/*.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "1-3ZD-YwvxVS",
        "outputId": "0bfd6331-9a62-49ea-c856-1efc74718e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"align_images.py\", line 33, in <module>\n",
            "    for img_name in [x for x in os.listdir(RAW_IMAGES_DIR) if x[0] not in '._']:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'raw'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x2880 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}