{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMkRiHm9BxT9qBaBYZLvSBd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GAN/blob/master/Toony_Yourself.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Toony Yourself**\n",
        "\n",
        "implementation: http://cedro3.com/ai/toonify-yourself/#comment-869\n",
        "\n",
        "original: "
      ],
      "metadata": {
        "id": "dfb-8Mp_vZVU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrUdKnhCs5P-",
        "outputId": "d87674c8-8575-4ed6-f341-738026f51f27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Total 269 (delta 0), reused 0 (delta 0), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (269/269), 2.32 MiB | 4.97 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n",
            "/content/stylegan2/stylegan2/stylegan2\n",
            "CPU says hello.\n",
            "GPU says hello.\n"
          ]
        }
      ],
      "source": [
        "#StyleGANをGit clone\n",
        "%tensorflow_version 1.x\n",
        "!git clone https://github.com/justinpinkney/stylegan2\n",
        "\n",
        "%cd stylegan2\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        " \n",
        "# フォルダーの作成\n",
        "!mkdir aligned\n",
        "!mkdir generated"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ffhqモデル(Baseモデル)とblendedモデルのダウンロード\n",
        "import pretrained_networks\n",
        "import gdown\n",
        "\n",
        " \n",
        "# use my copy of the blended model to save Doron's download bandwidth\n",
        "# get the original here https://mega.nz/folder/OtllzJwa#C947mCCdEfMCRTWnDcs4qw\n",
        "#blended_url = \"https://drive.google.com/uc?id=1H73TfV5gQ9ot7slSed_l-lim9X7pMRiU\"\n",
        "blended_url = \"https://drive.google.com/uc?id=1BRqqHWk_4BjNHLXTrpHkoxmZhGw3CU59\" \n",
        "ffhq_url = \"http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\"\n",
        "\n",
        "#エラーがでてうまくいかないので、ダイレクトにダウンロードすることにする \n",
        "#_, _, Gs_blended = pretrained_networks.load_networks(blended_url)\n",
        "#_, _, Gs = pretrained_networks.load_networks(ffhq_url)\n",
        "gdown.download(blended_url, quiet=False)\n",
        "gdown.download(ffhq_url, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "LaHIEZSItJe-",
        "outputId": "8d80aa4e-69cd-4fcb-9170-0d767132f75a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1BRqqHWk_4BjNHLXTrpHkoxmZhGw3CU59 \n",
            "\n",
            "Downloading...\n",
            "From: http://d36zk2xti64re0.cloudfront.net/stylegan2/networks/stylegan2-ffhq-config-f.pkl\n",
            "To: /content/stylegan2/stylegan2/stylegan2/stylegan2-ffhq-config-f.pkl\n",
            "100%|██████████| 382M/382M [00:01<00:00, 255MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stylegan2-ffhq-config-f.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**必要な関数を定義**"
      ],
      "metadata": {
        "id": "FdKJO8GavUwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像表示\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(30, 40))\n",
        "    files = glob.glob(folder)\n",
        "    files.sort()\n",
        "    images=[]\n",
        "    for i in range(len(files)):\n",
        "        img = Image.open(files[i])    \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(str(i), fontsize=20)               \n",
        "    plt.show()\n",
        "    plt.close()  \n",
        "\n",
        "# 潜在変数(latents)から生成した画像を表示\n",
        "import PIL.Image\n",
        "def display(latents):\n",
        "    \n",
        "    synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "  \n",
        "    fig = plt.figure(figsize=(30, 40))   \n",
        "    for i in range(len(latents)):\n",
        "        vec = latents[i].reshape(1,18,512)\n",
        "        images =  Gs_blended.components.synthesis.run(vec, randomize_noise=False, **synthesis_kwargs)  \n",
        "        images = images.transpose((0,2,3,1))     \n",
        "        PIL.Image.fromarray(images[0], 'RGB')   \n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images[0])\n",
        "        ax.imshow(image_plt)\n",
        "        ax.set_xlabel(str(i), fontsize=20)               \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# 潜在変数(latents)の順番を指定して、トランジションのGIFを作成する\n",
        "import os\n",
        "\n",
        "def generate_gif(latents, idx):\n",
        "\n",
        "    synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False), minibatch_size=8)\n",
        "\n",
        "    image_gif = []\n",
        "    os.makedirs('my/gif', exist_ok=True)\n",
        "    for j in range(len(idx)-1):\n",
        "        for i in range(20):\n",
        "            latent = latents[idx[j]]+(latents[idx[j+1]]-latents[idx[j]])*i/19\n",
        "            latent = latent.reshape(1, 18, 512)\n",
        "            images =  Gs_blended.components.synthesis.run(latent, randomize_noise=False, **synthesis_kwargs) \n",
        "            images = images.transpose((0,2,3,1)) \n",
        "            image_one = PIL.Image.fromarray(images[0], 'RGB')\n",
        "            image_gif.append(image_one.resize((256,256))) \n",
        "\n",
        "    image_gif[0].save('./my/gif/anime.gif', save_all=True, append_images=image_gif[1:],\n",
        "                      duration=100, loop=0) "
      ],
      "metadata": {
        "id": "qe2XL4y3vTl6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# サンプル写真のダウンロードと整形\n",
        "import os \n",
        "import shutil\n",
        "import requests\n",
        "\n",
        "\n",
        "# rawフォルダを作成\n",
        "try: \n",
        "    shutil.rmtree(\"/content/stylegan2/raw\")\n",
        "    print(\"directory deleted\")\n",
        "    print(\"\")\n",
        "except:\n",
        "    pass\n",
        "os.makedirs(\"/content/stylegan2/raw\", exist_ok=True)\n",
        "\n",
        "\n",
        "#Webから画像をダウンロードしてrawフォルダに格納\n",
        "url = \"https://images.unsplash.com/photo-1597223557154-721c1cecc4b0?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxzZWFyY2h8Mnx8aHVtYW4lMjBmYWNlfGVufDB8fDB8fA%3D%3D&w=1000&q=80\"\n",
        "file_name = \"/content/stylegan2/raw/sample.jpg\"\n",
        "\n",
        "response = requests.get(url)\n",
        "image = response.content\n",
        "with open(file_name, \"wb\") as aaa:\n",
        "    aaa.write(image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrgcSkltyGEm",
        "outputId": "54a5ece4-1f8b-4aa9-b777-7d132f62aa08"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "directory deleted\n",
            "\n",
            "aligned\t\t       generated\t       run_generator.py\n",
            "align_images.py        grid_vid.py\t       run_metrics.py\n",
            "blend_models.py        LICENSE.txt\t       run_projector.py\n",
            "dataset_tool.py        metrics\t\t       run_training.py\n",
            "dnnlib\t\t       pretrained_networks.py  stylegan2-ffhq-config-f.pkl\n",
            "Dockerfile\t       project_images.py       test_nvcc\n",
            "docs\t\t       projector.py\t       test_nvcc.cu\n",
            "fake_art_portrait.jpg  raw\t\t       training\n",
            "ffhq_dataset\t       README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fSjXu82gzyHl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 顔画像の切り取り\n",
        "!python align_images.py raw aligned\n",
        "display_pic('./aligned/*.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "1-3ZD-YwvxVS",
        "outputId": "0bfd6331-9a62-49ea-c856-1efc74718e7b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"align_images.py\", line 33, in <module>\n",
            "    for img_name in [x for x in os.listdir(RAW_IMAGES_DIR) if x[0] not in '._']:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'raw'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x2880 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}