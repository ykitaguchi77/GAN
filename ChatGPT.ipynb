{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU7wEjiJL4A/VRK053VL3p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GAN/blob/master/ChatGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "!pip install openai --q\n",
        "!pip install --upgrade deepl --q\n",
        "import openai\n",
        "import deepl\n",
        "import textwrap\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Deep_learning/api.txt\") as file:\n",
        "    #text = file.read()\n",
        "    i=1\n",
        "    key = []\n",
        "    while True:\n",
        "        include_break_line = file.readline() #改行が含まれた行\n",
        "        line = include_break_line.rstrip() #改行を取り除く\n",
        "        if line: #keyの読み込み\n",
        "            #print(f'{i}行目：{line}')\n",
        "            key.append(line)\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "# APIキーの準備\n",
        "#ngrok_aceess_token = key[5]\n",
        "openai.api_key = key[3]\n",
        "deepl_auth_key = key[1]\n",
        "\n",
        "translator = deepl.Translator(deepl_auth_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTce3wIiMyNe",
        "outputId": "be2c3733-36d9-467c-a6e5-213df652e70e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**ChatGPT configulation**\n",
        "question_translate_English= True #@param {type:\"boolean\"}\n",
        "answer_Japanese= False #@param {type:\"boolean\"}\n",
        "reset= False #@param {type:\"boolean\"}\n",
        "\n",
        "if \"text_input\" not in globals():\n",
        "    text_input = []\n",
        "if reset == True:\n",
        "    text_input = []\n",
        "\n",
        "\n",
        "def wrap(sentence):\n",
        "    wrap_list =  textwrap.wrap(sentence, 40)\n",
        "    output = '\\n'.join(wrap_list)\n",
        "    return(output)\n",
        "\n",
        "\n",
        "def interference(question):\n",
        "    question = question.replace('\\n', '') #前後の空白と改行を削除\n",
        "\n",
        "    if question_translate_English == True:\n",
        "        question_translated = translator.translate_text(question, target_lang=\"EN-US\").text.replace('\\n', '')\n",
        "        question = question_translated\n",
        "    else:\n",
        "        question = question\n",
        "\n",
        "    prompt = \"Q:\" + question +\"\\nA:\"\n",
        "\n",
        "    print(f\"{prompt}\")\n",
        "\n",
        "    text_input.append(question+\"\\nA:\")\n",
        "\n",
        "    prompt =  \",\".join(map(str, text_input)) # aaa,bbb,100,200,300 \n",
        "\n",
        "    response = openai.Completion.create(\n",
        "      model=\"text-davinci-003\",\n",
        "      prompt=prompt,\n",
        "      temperature=0.5,\n",
        "      max_tokens=1024,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0.0,\n",
        "      presence_penalty=0.0,\n",
        "      stop=[\"\\n\"])\n",
        "\n",
        "    answer = response['choices'][0]['text']\n",
        "    text_input.append(answer)\n",
        "\n",
        "    if answer_Japanese == True:\n",
        "        answer = translator.translate_text(response['choices'][0]['text'], target_lang=\"JA\").text\n",
        "    else:\n",
        "        answer = answer\n",
        "\n",
        "        \n",
        "    print(f\"{wrap(answer)} \\n\")\n",
        "\n",
        "    print(text_input)\n",
        "\n"
      ],
      "metadata": {
        "id": "Y8-pjNNBgII9"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "please go on bullets\n",
        "\"\"\"\n",
        "interference(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXm2qK5CeBhn",
        "outputId": "544c60e0-a786-4897-d433-bc9594cce622"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q:please go on bullets\n",
            "A:\n",
            " \n",
            "\n",
            "['I need you to act as a research assistant for a scientific article I am writing. I will provide you with specific questions and information, and I expect you to find relevant and credible sources to support my research. Your responses should include a summary of the main points from the sources, along with the full citation in the desired format (APA, MLA, etc.). Additionally, you should flag any potential issues or limitations in the sources you provide. The title of the article is: Real-time smartphone identification of corneal diseases displayed on computer screen using embedded deep-learning model. Please show me the bullets which I need to contain in the introduction. Please show me the bullets which I need to contain in the introduction.\\nA:', ' ', 'I need you to act as a research assistant for a scientific article I am writing. I will provide you with specific questions and information, and I expect you to find relevant and credible sources to support my research. Your responses should include a summary of the main points from the sources, along with the full citation in the desired format (APA, MLA, etc.). Additionally, you should flag any potential issues or limitations in the sources you provide. The title of the article is: Real-time smartphone identification of corneal diseases displayed on computer screen using embedded deep-learning model.\\nA:', ' Introduction Bullets: ', 'please go on bullets\\nA:', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.5,\n",
        "  max_tokens=1024,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\n",
        "\n",
        "answer = response['choices'][0]['text']\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HPTkseGmqBSi",
        "outputId": "893d98fe-d995-4673-e72e-ae1cf48b4c93"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = \"Q:\" + question + \"\\nA:\"\n",
        "\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.5,\n",
        "  max_tokens=1024,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\n",
        "\n",
        "answer = response['choices'][0]['text']\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "su6ytCEEkCYU",
        "outputId": "907a727e-433a-4144-f38e-ee56bf0a1e97"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = '''\n",
        "\n",
        "I need you to act as a research assistant for a scientific article I am writing. I will provide you with specific questions and information, and I expect you to find relevant and credible sources to support my research. Your responses should include a summary of the main points from the sources, along with the full citation in the desired format (APA, MLA, etc.). Additionally, you should flag any potential issues or limitations in the sources you provide. The title of the article is: \"Real-time smartphone identification of corneal diseases displayed on computer screen  using embedded deep-learning model.\n",
        "\" Please show me the bullets which I need to contain in the introduction.\n",
        "\n",
        "'''\n",
        "question.replace('\\n', '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "35f-2WyCm3E7",
        "outputId": "af74d204-d1c9-4057-f479-d6e9107bb120"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I need you to act as a research assistant for a scientific article I am writing. I will provide you with specific questions and information, and I expect you to find relevant and credible sources to support my research. Your responses should include a summary of the main points from the sources, along with the full citation in the desired format (APA, MLA, etc.). Additionally, you should flag any potential issues or limitations in the sources you provide. The title of the article is: \"Real-time smartphone identification of corneal diseases displayed on computer screen  using embedded deep-learning model.\" Please show me the bullets which I need to contain in the introduction.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from traitlets.config.application import T\n",
        "#@title #**ChatGPT input form**\n",
        "\n",
        "question = 'I need you to act as a research assistant for a scientific article I am writing. I will provide you with specific questions and information, and I expect you to find relevant and credible sources to support my research. Your responses should include a summary of the main points from the sources, along with the full citation in the desired format (APA, MLA, etc.). Additionally, you should flag any potential issues or limitations in the sources you provide. The title of the article is: \"Real-time smartphone identification of corneal diseases displayed on computer screen  using embedded deep-learning model.\" Please show me the bullets which I need to contain in the introduction.'#@param {type:\"string\"}\n",
        "answer_Japanese= False #@param {type:\"boolean\"}\n",
        "reset= True #@param {type:\"boolean\"}\n",
        "\n",
        "if \"text_input\" not in globals():\n",
        "    text_input = []\n",
        "if reset == True:\n",
        "    text_input = []\n",
        "\n",
        "prompt = \"Q:\" + translator.translate_text(question, target_lang=\"EN-US\").text +\"\\n A:\"\n",
        "text_input.append(prompt)\n",
        "\n",
        "prompt =  \",\".join(map(str, text_input)) # aaa,bbb,100,200,300 \n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0.5,\n",
        "  max_tokens=1024,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\n",
        "\n",
        "answer = response['choices'][0]['text']\n",
        "text_input.append(answer)\n",
        "\n",
        "if answer_Japanese == True:\n",
        "    answer = translator.translate_text(response['choices'][0]['text'], target_lang=\"JA\").text\n",
        "else:\n",
        "    answer = answer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Q: {question} \\nA: {answer}\")\n",
        "\n",
        "\n",
        "print(text_input)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlYHLhWF90Zp",
        "outputId": "80cc6b74-57fe-4c95-fcc4-23749691f518"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: I need you to act as a research assistant for a scientific article I am writing. I will provide you with specific questions and information, and I expect you to find relevant and credible sources to support my research. Your responses should include a summary of the main points from the sources, along with the full citation in the desired format (APA, MLA, etc.). Additionally, you should flag any potential issues or limitations in the sources you provide. The title of the article is: \"Real-time smartphone identification of corneal diseases displayed on computer screen  using embedded deep-learning model.\" Please show me the bullets which I need to contain in the introduction. \n",
            "A:  \n",
            "['Q:I need you to act as a research assistant for a scientific article I am writing. I will provide you with specific questions and information, and I expect you to find relevant and credible sources to support my research. Your responses should include a summary of the main points from the sources, along with the full citation in the desired format (APA, MLA, etc.). Additionally, you should flag any potential issues or limitations in the sources you provide. The title of the article is: \"Real-time smartphone identification of corneal diseases displayed on computer screen using embedded deep-learning model.\" Please show me the bullets which I need to contain in the introduction.\\n A:', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J-3qFtRKfJGG",
        "outputId": "c81c15e2-b985-442d-a25e-4d105e92f53b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53DzQIWIac6O",
        "outputId": "4b9eb45f-4501-4edc-841a-8317e5c9268d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Q:Where can I buy a salad?\\n A:', ' You can buy a salad at most grocery stores, restaurants, and fast food establishments. You can also make your own salad at home using fresh ingredients.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=1024,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\n",
        "\n",
        "answer = response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "4FUOV7-4Yavf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sOmw1sNhT9WZ",
        "outputId": "34f7c9e6-8393-4ab3-e2e4-58bf1de419e6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qs-p_uuIj03",
        "outputId": "5e4f1917-8650-4690-d3f8-12497644d77e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 質問\n",
        "question = 'I need you to act as a research assistant for a scientific article I am writing. I will provide you with specific questions and information, and I expect you to find relevant and credible sources to support my research. Your responses should include a summary of the main points from the sources, along with the full citation in the desired format (APA, MLA, etc.). Additionally, you should flag any potential issues or limitations in the sources you provide. The title of the article is: \"Real-time smartphone identification of corneal diseases displayed on computer screen  using embedded deep-learning model.\" Please show me the bullets which I need to contain in the introduction.'\n",
        "\n",
        "# プロンプト\n",
        "prompt = \"Q:\" + question + \"\\nA:\"\n",
        "\n",
        "# 推論\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=1024,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\n",
        "\n",
        "# 回答\n",
        "answer = response['choices'][0]['text']\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 質問\n",
        "question = \"セガが開発したゲームのおすすめを教えて下さい。\"\n",
        "\n",
        "# プロンプト\n",
        "prompt = \"Q:\" + translator.translate_text(question, target_lang=\"EN-US\").text + \"\\nA:\"\n",
        "\n",
        "# 推論\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=prompt,\n",
        "  temperature=0,\n",
        "  max_tokens=1024,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0,\n",
        "  stop=[\"\\n\"])\n",
        "\n",
        "# 回答\n",
        "answer = translator.translate_text(response['choices'][0]['text'], target_lang=\"JA\").text\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtS-p_EE9rDA",
        "outputId": "de8fddc3-1365-49ae-e4e5-94e074500b72"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "セガが開発した最も人気のあるゲームのひとつは、「ソニック・ザ・ヘッジホッグ」である。セガが開発した他の人気ゲームには、クレイジータクシー、バーチャファイター、ファンタシースター、ヤクザがある。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "previous_response = \"\"\n",
        "\n",
        "\n",
        "text_input = input(\"Enter your text: \")\n",
        "prompt = f\"{previous_response} {text_input}\"\n",
        "\n",
        "completions = openai.Completion.create(\n",
        "    engine=\"text-davinci-002\",\n",
        "    prompt=prompt,\n",
        "    max_tokens=1024,\n",
        "    n=1,\n",
        "    stop=None,\n",
        "    temperature=0.5,\n",
        ")\n",
        "message = completions.choices[0].text\n",
        "previous_response = message\n",
        "print(message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JNDqJ8ZHVzgI",
        "outputId": "b7805dfa-6a5b-4f10-c2d0-a8e694dce4f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your text: 明日の天気は？\n",
            "\n",
            "\n",
            "It's going to be sunny tomorrow.\n",
            "Enter your text: じゃあ傘はいりますかね？\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Would you like to bring your umbrella?\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "You're welcome. どういたしまして。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you. ありがとう。\n",
            "\n",
            "\n",
            "\n",
            "Thank you.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ef05a0cf93b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your text: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtext_input\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}