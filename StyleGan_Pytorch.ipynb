{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled27.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMtGbw009s2WkfTTm3GC/eM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GAN/blob/master/StyleGan_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLrrfKWfKL2b",
        "colab_type": "text"
      },
      "source": [
        "#StyleGAN実行\n",
        "https://github.com/pacifinapacific/StyleGAN_LatentEditor/blob/master/StyleGAN_editor.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TdqFMFhKlsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "1cad9402-c7a4-4a2d-84ab-1337028fe4c1"
      },
      "source": [
        "# Install TensorFlow\n",
        "!pip install tensorflow==1.12.0\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 57kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.3.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.18.3)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.28.1)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 52.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.2.1)\n",
            "Installing collected packages: tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l880gjTvJY4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d1fb73ce-2bfe-479b-8bcd-a1d7781a3455"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq73r7wQJT0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "8b24323b-8ef9-4f80-ae43-35f598f30214"
      },
      "source": [
        "import os\n",
        "path = '/content/drive/My Drive/Deep_learning/StyleGAN_LatentEditor'\n",
        "\n",
        "#作業ディレクトリをpathに移動する\n",
        "os.chdir(path)\n",
        "\n",
        "#作業ディレクトリ直下のファイルを確認\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "align_images.py        latent_W\t\t    semantic_edit.py\n",
            "dnnlib\t\t       make_morphgif.py     source_image\n",
            "encode_image.py        perceptual_model.py  StyleGAN_editor.ipynb\n",
            "face_alignment.py      __pycache__\t    stylegan_layers.py\n",
            "facial_exchange.py     read_image.py\t    weight_convert.py\n",
            "image_crossover.py     README.txt\t    weight_files\n",
            "image_morphing.py      save_image\n",
            "landmarks_detector.py  save_result\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Uaa-cLKJ51",
        "colab_type": "text"
      },
      "source": [
        "#TensorFlowのweight → Pytorchのweight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SzfzPnXKKBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "c38a2aeb-e8a3-4240-f0fd-623a82514425"
      },
      "source": [
        "#!python weight_convert.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "sd only g_synthesis.blocks.8x8.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.16x16.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.32x32.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.64x64.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.128x128.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.256x256.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.512x512.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only g_synthesis.blocks.1024x1024.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 1024x1024.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 1024x1024.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 512x512.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 512x512.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 256x256.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 256x256.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 128x128.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 128x128.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 64x64.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 64x64.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 32x32.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 32x32.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 16x16.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 16x16.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
            "sd only 8x8.blur.kernel torch.Size([1, 1, 3, 3])\n",
            "sd only 8x8.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1tXMojqKxMM",
        "colab_type": "text"
      },
      "source": [
        "#**[1]潜在変数の推定**\n",
        "(Abdal, R., Qin, Y., & Wonka, P. (2019). Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkAAnmlcKweT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ac6c546d-e23d-436a-fc4d-ac69a79e1819"
      },
      "source": [
        "!mkdir save_image\n",
        "!mkdir save_image/encode1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘save_image’: File exists\n",
            "mkdir: cannot create directory ‘save_image/encode1’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM_BonYbLADc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f9a4e6fa-fdd2-4cb6-d706-c4e8222f1c0e"
      },
      "source": [
        "!python image_morphing.py --latent_file1 latent_W/0.npy --latent_file2 latent_W/sample.npy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"image_morphing.py\", line 71, in <module>\n",
            "    main()\n",
            "  File \"image_morphing.py\", line 49, in main\n",
            "    latents_1=np.load(args.latent_file2)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\", line 428, in load\n",
            "    fid = open(os_fspath(file), \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'latent_W/sample.npy'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ArSF8GsLQRz",
        "colab_type": "text"
      },
      "source": [
        "#**morph画像をgifとして保存**\n",
        "save_result以下にgif\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIGPZ4-yLAF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2d6d2fd-f779-4524-ec23-4cc49aec5e67"
      },
      "source": [
        "!mkdir save_result"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘save_result’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hARV2OVVLAID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "df8cc85f-cd63-4011-9b27-456fa2bb6ce1"
      },
      "source": [
        "!python make_morphgif.py\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "Traceback (most recent call last):\n",
            "  File \"make_morphgif.py\", line 32, in <module>\n",
            "    images[0].save('save_result/morph.gif' , save_all = True , append_images = images[1::2] , duration = 100 , loop = 0)\n",
            "IndexError: list index out of range\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOdKxtRxLt2b",
        "colab_type": "text"
      },
      "source": [
        "#**[2]Image Crossover**\n",
        "(Abdal, R., Qin, Y., & Wonka, P. (2019). Image2StyleGAN++: How to Edit the Embedded Images? )<br>\n",
        "save_image/crossover/以下に生成画像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyKSvsZvLtOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2c0452c-14e5-445e-a636-63f194bd0293"
      },
      "source": [
        "!mkdir save_image/crossover"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘save_image/crossover’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va5O6PfhLtRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "outputId": "507365ba-9410-4cbf-94b3-6fc9f83693fb"
      },
      "source": [
        "!python image_crossover.py --src_im1  source_image/joker.png --src_im2  source_image/0.png --mask source_image/Blur_mask.png --iteration 1500"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n",
            "100% 528M/528M [00:02<00:00, 247MB/s]\n",
            "Start\n",
            "iter0: loss -- 6.047449111938477,  loss0 --4.542577743530273,  loss1 --1.5048714876174927\n",
            "iter10: loss -- 4.66278600692749,  loss0 --2.6844351291656494,  loss1 --1.9783509969711304\n",
            "iter20: loss -- 4.356183052062988,  loss0 --2.6590285301208496,  loss1 --1.6971544027328491\n",
            "iter30: loss -- 4.1302995681762695,  loss0 --2.550196409225464,  loss1 --1.5801030397415161\n",
            "iter40: loss -- 3.9723610877990723,  loss0 --2.482774257659912,  loss1 --1.4895867109298706\n",
            "iter50: loss -- 3.8139185905456543,  loss0 --2.408419609069824,  loss1 --1.4054991006851196\n",
            "iter60: loss -- 3.695916175842285,  loss0 --2.3301219940185547,  loss1 --1.365794062614441\n",
            "iter70: loss -- 3.5308032035827637,  loss0 --2.239952325820923,  loss1 --1.2908509969711304\n",
            "iter80: loss -- 3.4174797534942627,  loss0 --2.186795473098755,  loss1 --1.2306842803955078\n",
            "iter90: loss -- 3.3204586505889893,  loss0 --2.1248443126678467,  loss1 --1.1956143379211426\n",
            "iter100: loss -- 3.252011775970459,  loss0 --2.019883155822754,  loss1 --1.232128620147705\n",
            "iter110: loss -- 3.153705596923828,  loss0 --1.9473780393600464,  loss1 --1.2063274383544922\n",
            "iter120: loss -- 3.04764986038208,  loss0 --1.8514474630355835,  loss1 --1.1962025165557861\n",
            "iter130: loss -- 2.9648425579071045,  loss0 --1.8173552751541138,  loss1 --1.1474872827529907\n",
            "iter140: loss -- 2.8911828994750977,  loss0 --1.7234268188476562,  loss1 --1.167756199836731\n",
            "iter150: loss -- 2.7924036979675293,  loss0 --1.6673219203948975,  loss1 --1.1250817775726318\n",
            "iter160: loss -- 2.745551586151123,  loss0 --1.6412640810012817,  loss1 --1.1042875051498413\n",
            "iter170: loss -- 2.7272603511810303,  loss0 --1.5849764347076416,  loss1 --1.1422839164733887\n",
            "iter180: loss -- 2.6371078491210938,  loss0 --1.5278693437576294,  loss1 --1.1092383861541748\n",
            "iter190: loss -- 2.584425449371338,  loss0 --1.4942868947982788,  loss1 --1.0901384353637695\n",
            "iter200: loss -- 2.5998916625976562,  loss0 --1.5031355619430542,  loss1 --1.0967562198638916\n",
            "iter210: loss -- 2.872126579284668,  loss0 --1.6062946319580078,  loss1 --1.2658320665359497\n",
            "iter220: loss -- 2.727445125579834,  loss0 --1.4782615900039673,  loss1 --1.2491836547851562\n",
            "iter230: loss -- 2.6252191066741943,  loss0 --1.4372888803482056,  loss1 --1.1879302263259888\n",
            "iter240: loss -- 2.5989785194396973,  loss0 --1.4256378412246704,  loss1 --1.1733405590057373\n",
            "iter250: loss -- 2.4263739585876465,  loss0 --1.3971675634384155,  loss1 --1.0292065143585205\n",
            "iter260: loss -- 2.377045154571533,  loss0 --1.356155276298523,  loss1 --1.0208898782730103\n",
            "iter270: loss -- 2.388033390045166,  loss0 --1.335006594657898,  loss1 --1.0530266761779785\n",
            "iter280: loss -- 2.4490747451782227,  loss0 --1.371791124343872,  loss1 --1.0772837400436401\n",
            "iter290: loss -- 2.358088254928589,  loss0 --1.3063688278198242,  loss1 --1.0517194271087646\n",
            "iter300: loss -- 2.288501739501953,  loss0 --1.2913904190063477,  loss1 --0.9971112608909607\n",
            "iter310: loss -- 2.301269054412842,  loss0 --1.3109819889068604,  loss1 --0.9902871251106262\n",
            "iter320: loss -- 2.2419052124023438,  loss0 --1.2620303630828857,  loss1 --0.9798749685287476\n",
            "iter330: loss -- 2.2217726707458496,  loss0 --1.2441718578338623,  loss1 --0.9776007533073425\n",
            "iter340: loss -- 2.403219223022461,  loss0 --1.331347942352295,  loss1 --1.0718711614608765\n",
            "iter350: loss -- 2.384178638458252,  loss0 --1.3315507173538208,  loss1 --1.0526280403137207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3c7H-kRMHUs",
        "colab_type": "text"
      },
      "source": [
        "#**[3] 表情の変換** \n",
        "(Yang, C., Lim, S.-N., & Ai, F. (n.d.). Unconstrained Facial Expression Transfer using Style-based Generator)<br>\n",
        "save_image/exchange/以下に生成画像"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhtW2dkoLtTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir save_image/exchange\n",
        "!mkdir save_image/exchange/a\n",
        "!mkdir save_image/exchange/e\n",
        "!mkdir save_image/exchange/result1\n",
        "!mkdir save_image/exchange/result2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDqb6ollLtVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python facial_exchange.py --src_im1  source_image/sample.png --src_im2  source_image/0.png  --iteration 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE1BajdYMqqu",
        "colab_type": "text"
      },
      "source": [
        "#**[4] 顔属性のmorphing**\n",
        "(Shen, Y., Gu, J., Tang, X., & Zhou, B. (2019).Interpreting the Latent Space of GANs for Semantic Face Editing)<br>\n",
        "save_image/boundary/以下に生成画像\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjB0hoAsLtaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir save_image/boundary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4nGys2qLtcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python semantic_edit.py --latent_file  latent_W/0.npy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbCkO9AENLgy",
        "colab_type": "text"
      },
      "source": [
        "#**[5]自前で用意した画像で試したい方へ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PApau_U1NKut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir img\n",
        "!mkdir al_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mCY33DUNfgd",
        "colab_type": "text"
      },
      "source": [
        "入力画像を1024×1024にリサイズしかつalignする必要があります\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uajobWKLteT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#以下のセルでdlibを用いてそれを実行します。 imgディレクトリに用意した画像を置きコードを実行するとal_img内にalignされた画像が置かれます。後はsource_imageディレクトリに移して各セルの引数を変更してください\n",
        "!python align_images.py img/ al_img/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNthbd_hLAKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}