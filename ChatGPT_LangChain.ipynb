{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYIVkp8fF1ZPIhoR/71GQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GAN/blob/master/ChatGPT_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**LangChain APP**\n",
        "\n",
        "https://qiita.com/wwwcojp/items/c7f43c5f964b8db8a890\n",
        "\n",
        "https://note.com/npaka/n/n6b7a07e492f1"
      ],
      "metadata": {
        "id": "7sk4E_3TKggH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OfGbm9CHRcG",
        "outputId": "1429bbec-f2bc-4214-a725-af5c55e5de97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# パッケージのインストール\n",
        "!pip install langchain --q\n",
        "!pip install openai --q\n",
        "!pip install google-search-results --q\n",
        "!pip install --upgrade deepl --q\n",
        "import openai\n",
        "import deepl\n",
        "import textwrap\n",
        "import pandas as pd\n",
        "\n",
        "# パッケージのインポート\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Deep_learning/api.txt\") as file:\n",
        "    #text = file.read()\n",
        "    i=1\n",
        "    key = []\n",
        "    while True:\n",
        "        include_break_line = file.readline() #改行が含まれた行\n",
        "        line = include_break_line.rstrip() #改行を取り除く\n",
        "        if line: #keyの読み込み\n",
        "            #print(f'{i}行目：{line}')\n",
        "            key.append(line)\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "# APIキーの準備\n",
        "# #ngrok_aceess_token = key[5]\n",
        "# openai.api_key = key[3]\n",
        "# deepl_auth_key = key[1]\n",
        "# serp_api_key = key[7]\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = key[3]\n",
        "os.environ[\"SERPAPI_API_KEY\"] = key[7]"
      ],
      "metadata": {
        "id": "Xq40S0FgKt43"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLMの準備準備\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# ツールの準備\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# エージェントの準備\n",
        "agent = initialize_agent(\n",
        "    tools, \n",
        "    llm, \n",
        "    agent=\"zero-shot-react-description\", \n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "eFZ7FsM5Nb2u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# エージェントの実行\n",
        "agent.run(\"おでこにヒアルロン酸を注入する際の合併症は？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "fO9PAw__Nptt",
        "outputId": "35f964c5-32c3-4c88-f1ad-c2607ccd9b9c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out what the complications of injecting hyaluronic acid into the forehead are.\n",
            "Action: Search\n",
            "Action Input: Hyaluronic acid forehead injection complications\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mFortunately, over 90% of adverse events from the use of HA fillers are mild and transient. These include injection site redness, swelling, or bruising. However, disastrous outcomes can occur, including necrosis, vision loss, and cerebrovascular accidents.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the potential complications of injecting hyaluronic acid into the forehead.\n",
            "Final Answer: The potential complications of injecting hyaluronic acid into the forehead include injection site redness, swelling, bruising, necrosis, vision loss, and cerebrovascular accidents.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The potential complications of injecting hyaluronic acid into the forehead include injection site redness, swelling, bruising, necrosis, vision loss, and cerebrovascular accidents.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3xE_sbwzOFEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**例を見ながら勉強**"
      ],
      "metadata": {
        "id": "SUlUp0zVVUjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 基本的な入出力"
      ],
      "metadata": {
        "id": "9mNcQ5oCYYuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# モデル名を指定しない場合、「text-davinci-003」が利用されます\n",
        "llm = OpenAI(temperature=0.9)\n",
        "text = \"国立大学法人東京工業大学と国立大学法人東京医科歯科大学が合併しました。ついクスっと笑ってしまう新名称を考えてください。\"\n",
        "print(llm(prompt=text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z6aNrfhVZfJ",
        "outputId": "c5beecf4-5592-4105-fc93-0523ca8668a4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "「東京テクノロジー医科歯科大学」\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PromptTemplate\n",
        "\n",
        "ユーザー入力や複数出力に対応"
      ],
      "metadata": {
        "id": "Kxp3-xVlXTDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"target\"],\n",
        "    template=\"技術記事のタイトルをよしなに生成してくれるAIの{target}を考えてください。\",\n",
        ")\n",
        "print(llm(prompt=prompt.format(target=\"セールスポイント\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj0WWZaDVm9i",
        "outputId": "7e6ddbda-3ddf-455b-81d7-174289eed40b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "・最新のテクノロジー分野で有効な技術に関する記事タイトルを自動生成するAIを提供します。\n",
            "\n",
            "・最新の研究成果を内部で解析して、記事タイトルに適したワードを抽出し、効率的な記事タイトルを提供します。\n",
            "\n",
            "・記事タイトルの作成にお金や時間を節約します。\n",
            "\n",
            "・テクノロジーを専門とする専門家がいなくても、より良質な記事タイトルをつくることができます。\n",
            "\n",
            "・新しい技\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chains\n",
        "\n",
        "指定した順番で作業を行う"
      ],
      "metadata": {
        "id": "aBIHu_dyYTyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(temperature=.7)\n",
        "template = \"\"\"あなたは新商品の開発を担当しています。新商品のターゲットが与えられたら、ターゲットに売れる新商品のアイデアを出してください。\n",
        "\n",
        "ターゲット: {target}\n",
        "担当者: 以下が新商品のアイデアです。\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"target\"], template=template)\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "llm = OpenAI(temperature=.7)\n",
        "template = \"\"\"あなたは経営者です。新商品のアイデアが与えられたら、経営者の観点から批判的にレビューをしてください。\n",
        "\n",
        "アイデア:\n",
        "{idea}\n",
        "経営者：\n",
        "\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"idea\"], template=template)\n",
        "review_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "overall_chain = SimpleSequentialChain(chains=[synopsis_chain, review_chain], verbose=True)\n",
        "review = overall_chain.run(\"通勤に1時間以上かかっている20代の男性\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svt7PSlwXHyR",
        "outputId": "36af3952-d35e-404f-9532-f41472c81f78"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "1.高性能のノートPC: 20代の男性にとって、ノートPCは非常に便利なツールです。ノートPCは、高性能なパフォーマンスを提供しながら、コンパクトで軽量なので、通勤中の仕事や勉強などに最適です。\n",
            "\n",
            "2. 無線LAN・モバイルルーター: 通勤中の電車内でもインターネット接続ができる無線LAN・モバイルルーターは、20代の男性にとって便利な商品です。インターネット接続ができるので、電車内でも仕事や勉強を続\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "1.高性能のノートPC: 確かに、20代の男性にとって高性能のノートPCは非常に便利なツールです。しかし、値段が高くなりすぎると、市場から受け入れられない可能性があります。また、他のノートPCとの差別化を図るため、価値を高めるための新しい機能を提供する必要があるでしょう。\n",
            "\n",
            "2.無線LAN・モバイルルーター: 確かに、20代の男性にとって便利な商品ですが、他の製品との差別化を行う\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agents\n",
        "\n",
        "Chainをどのような順番で動かすかを決定する\n",
        "\n",
        "・zero-shot-react-description：  Toolのdescription（説明文）をもとに、どのToolを選択するか決定する\n",
        "\n",
        "・react-docstore:  ドキュメントを検索するSearchと、検索結果から用語を探すLookupという2つのToolを用意\n",
        "\n",
        "・self-ask-with-search:  Google検索等を用いて、自問自答・検索を繰り返しながら答えを導く\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5wOEG9hraXZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import LLMMathChain, SerpAPIWrapper\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "search = SerpAPIWrapper()\n",
        "llm_math_chain = LLMMathChain(llm=llm, verbose=True)\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=llm_math_chain.run,\n",
        "        description=\"useful for when you need to answer questions about math\"\n",
        "    )\n",
        "]\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "agent.run(\"日本で一番高い山の高さは何メートルですか?その高さの5乗根を求めてください。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "id": "0xn9d4mCbLTJ",
        "outputId": "63a855b8-8730-430a-849e-e10b31712e2f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find the height of the highest mountain in Japan and then calculate its fifth root.\n",
            "Action: Search\n",
            "Action Input: \"highest mountain in Japan\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mMount Fuji\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find the height of Mount Fuji\n",
            "Action: Search\n",
            "Action Input: \"height of Mount Fuji\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m12,388′\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to convert this to meters\n",
            "Action: Calculator\n",
            "Action Input: 12,388 * 0.3048\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "12,388 * 0.3048\u001b[32;1m\u001b[1;3m\n",
            "Answer: 3760.544\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3760.544\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the fifth root of 3760.544\n",
            "Action: Calculator\n",
            "Action Input: 3760.544^(1/5)\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "3760.544^(1/5)\u001b[32;1m\u001b[1;3m\n",
            "```python\n",
            "print(3760.544**(1/5))\n",
            "```\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m5.188599325914775\n",
            "\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 5.188599325914775\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The height of the highest mountain in Japan is 3760.544 meters and its fifth root is 5.188599325914775.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The height of the highest mountain in Japan is 3760.544 meters and its fifth root is 5.188599325914775.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory\n",
        "\n",
        "前までの会話を覚えておく\n",
        "\n",
        "・  ConversationBufferMemory  前段までの入力・出力をそのまま記憶する\n",
        "\n",
        "・  ConversationalBufferWindowMemory  k段前までの入力・出力をそのまま記憶する\n",
        "\n",
        "・  ConversationSummaryMemory  前段までの入力・出力をLLMでサマライズして記憶する"
      ],
      "metadata": {
        "id": "yDlM89GFcodW"
      }
    }
  ]
}