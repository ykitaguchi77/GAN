{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3EH5WDUJzGSzd4BMKb9Nw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/GAN/blob/master/ChatGPT_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**LangChain APP**\n",
        "\n",
        "https://qiita.com/wwwcojp/items/c7f43c5f964b8db8a890\n",
        "\n",
        "https://note.com/npaka/n/n6b7a07e492f1"
      ],
      "metadata": {
        "id": "7sk4E_3TKggH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OfGbm9CHRcG",
        "outputId": "b65ea77e-6e97-4787-a05f-a23da875655f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# パッケージのインストール\n",
        "!pip install langchain --q\n",
        "!pip install openai --q\n",
        "!pip install google-search-results --q\n",
        "!pip install --upgrade deepl --q\n",
        "import openai\n",
        "import deepl\n",
        "import textwrap\n",
        "import pandas as pd\n",
        "\n",
        "# パッケージのインポート\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Deep_learning/api.txt\") as file:\n",
        "    #text = file.read()\n",
        "    i=1\n",
        "    key = []\n",
        "    while True:\n",
        "        include_break_line = file.readline() #改行が含まれた行\n",
        "        line = include_break_line.rstrip() #改行を取り除く\n",
        "        if line: #keyの読み込み\n",
        "            #print(f'{i}行目：{line}')\n",
        "            key.append(line)\n",
        "            i += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "# APIキーの準備\n",
        "# #ngrok_aceess_token = key[5]\n",
        "# openai.api_key = key[3]\n",
        "# deepl_auth_key = key[1]\n",
        "# serp_api_key = key[7]\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = key[3]\n",
        "os.environ[\"SERPAPI_API_KEY\"] = key[7]\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = key[9]\n",
        "os.environ[\"GOOGLE_API_KEY\"] = key[11]"
      ],
      "metadata": {
        "id": "Xq40S0FgKt43"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLMの準備準備\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# ツールの準備\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# エージェントの準備\n",
        "agent = initialize_agent(\n",
        "    tools, \n",
        "    llm, \n",
        "    agent=\"zero-shot-react-description\", \n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "eFZ7FsM5Nb2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# エージェントの実行\n",
        "agent.run(\"おでこにヒアルロン酸を注入する際の合併症は？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "fO9PAw__Nptt",
        "outputId": "35f964c5-32c3-4c88-f1ad-c2607ccd9b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out what the complications of injecting hyaluronic acid into the forehead are.\n",
            "Action: Search\n",
            "Action Input: Hyaluronic acid forehead injection complications\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mFortunately, over 90% of adverse events from the use of HA fillers are mild and transient. These include injection site redness, swelling, or bruising. However, disastrous outcomes can occur, including necrosis, vision loss, and cerebrovascular accidents.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the potential complications of injecting hyaluronic acid into the forehead.\n",
            "Final Answer: The potential complications of injecting hyaluronic acid into the forehead include injection site redness, swelling, bruising, necrosis, vision loss, and cerebrovascular accidents.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The potential complications of injecting hyaluronic acid into the forehead include injection site redness, swelling, bruising, necrosis, vision loss, and cerebrovascular accidents.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3xE_sbwzOFEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**例を見ながら勉強**"
      ],
      "metadata": {
        "id": "SUlUp0zVVUjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 基本的な入出力"
      ],
      "metadata": {
        "id": "9mNcQ5oCYYuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# モデル名を指定しない場合、「text-davinci-003」が利用されます\n",
        "llm = OpenAI(temperature=0.9)\n",
        "text = \"国立大学法人東京工業大学と国立大学法人東京医科歯科大学が合併しました。ついクスっと笑ってしまう新名称を考えてください。\"\n",
        "print(llm(prompt=text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z6aNrfhVZfJ",
        "outputId": "c5beecf4-5592-4105-fc93-0523ca8668a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "「東京テクノロジー医科歯科大学」\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PromptTemplate\n",
        "\n",
        "ユーザー入力や複数出力に対応"
      ],
      "metadata": {
        "id": "Kxp3-xVlXTDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"target\"],\n",
        "    template=\"技術記事のタイトルをよしなに生成してくれるAIの{target}を考えてください。\",\n",
        ")\n",
        "print(llm(prompt=prompt.format(target=\"セールスポイント\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj0WWZaDVm9i",
        "outputId": "7e6ddbda-3ddf-455b-81d7-174289eed40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "・最新のテクノロジー分野で有効な技術に関する記事タイトルを自動生成するAIを提供します。\n",
            "\n",
            "・最新の研究成果を内部で解析して、記事タイトルに適したワードを抽出し、効率的な記事タイトルを提供します。\n",
            "\n",
            "・記事タイトルの作成にお金や時間を節約します。\n",
            "\n",
            "・テクノロジーを専門とする専門家がいなくても、より良質な記事タイトルをつくることができます。\n",
            "\n",
            "・新しい技\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chains\n",
        "\n",
        "指定した順番で作業を行う\n",
        "\n",
        "・SimpleSequentialChain : 入出力を1つずつ持つチェーンを繋げるシンプルなチェーン\n",
        "\n",
        "・SequentialChain : 入出力を複数持つチェーンを繋げる一般的なチェーン"
      ],
      "metadata": {
        "id": "aBIHu_dyYTyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# プロンプトテンプレートの準備\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"{product}を作る新会社名の案を1つ出してください\",\n",
        ")\n",
        "\n",
        "# LLMChainの準備\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# LLMChainの実行\n",
        "print(chain.run(\"家庭用ロボット\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKDNKQZApWFi",
        "outputId": "605a3627-a259-4ecb-8535-ecb03d0d20fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ジョイポット・ファミリー\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SimpleSequentialChainの例2つ"
      ],
      "metadata": {
        "id": "l1t0RAmSrupn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = OpenAI(temperature=.7)\n",
        "template = \"\"\"あなたは新商品の開発を担当しています。新商品のターゲットが与えられたら、ターゲットに売れる新商品のアイデアを出してください。\n",
        "\n",
        "ターゲット: {target}\n",
        "担当者: 以下が新商品のアイデアです。\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"target\"], template=template)\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "llm = OpenAI(temperature=.7)\n",
        "template = \"\"\"あなたは経営者です。新商品のアイデアが与えられたら、経営者の観点から批判的にレビューをしてください。\n",
        "\n",
        "アイデア:\n",
        "{idea}\n",
        "経営者：\n",
        "\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"idea\"], template=template)\n",
        "review_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "overall_chain = SimpleSequentialChain(chains=[synopsis_chain, review_chain], verbose=True)\n",
        "review = overall_chain.run(\"通勤に1時間以上かかっている20代の男性\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svt7PSlwXHyR",
        "outputId": "36af3952-d35e-404f-9532-f41472c81f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "1.高性能のノートPC: 20代の男性にとって、ノートPCは非常に便利なツールです。ノートPCは、高性能なパフォーマンスを提供しながら、コンパクトで軽量なので、通勤中の仕事や勉強などに最適です。\n",
            "\n",
            "2. 無線LAN・モバイルルーター: 通勤中の電車内でもインターネット接続ができる無線LAN・モバイルルーターは、20代の男性にとって便利な商品です。インターネット接続ができるので、電車内でも仕事や勉強を続\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "1.高性能のノートPC: 確かに、20代の男性にとって高性能のノートPCは非常に便利なツールです。しかし、値段が高くなりすぎると、市場から受け入れられない可能性があります。また、他のノートPCとの差別化を図るため、価値を高めるための新しい機能を提供する必要があるでしょう。\n",
            "\n",
            "2.無線LAN・モバイルルーター: 確かに、20代の男性にとって便利な商品ですが、他の製品との差別化を行う\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://note.com/npaka/n/n61ad59380a43\n",
        "\n",
        "# LLMの定義\n",
        "llm = OpenAI(temperature=.7)\n",
        "\n",
        "\n",
        "# 1つ目のチェーンの準備 : 劇のタイトルからあらすじを生成\n",
        "\n",
        "# テンプレートの準備\n",
        "template = \"\"\"あなたは劇作家です。劇のタイトルが与えられた場合、そのタイトルのあらすじを書くのがあなたの仕事です。\n",
        "\n",
        "タイトル:{title}\n",
        "あらすじ:\"\"\"\n",
        "\n",
        "# プロンプトテンプレートの準備\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"title\"], \n",
        "    template=template\n",
        ")\n",
        "\n",
        "# LLMChainの準備\n",
        "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "\n",
        "\n",
        "# 2つ目のチェーン : 劇のあらすじからレビューを生成\n",
        "\n",
        "# LLMの準備準備\n",
        "llm = OpenAI(temperature=.7)\n",
        "\n",
        "# テンプレートの準備\n",
        "template = \"\"\"あなたは演劇評論家です。 劇のあらすじが与えられた場合、そのあらすじのレビューを書くのがあなたの仕事です。\n",
        "\n",
        "あらすじ:\n",
        "{synopsis}\n",
        "レビュー:\"\"\"\n",
        "\n",
        "# プロンプトテンプレートの準備\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"synopsis\"], \n",
        "    template=template\n",
        ")\n",
        "\n",
        "# LLMChainの準備\n",
        "review_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "# SimpleSequentialChainで2つのチェーンを繋ぐ\n",
        "overall_chain = SimpleSequentialChain(\n",
        "    chains=[synopsis_chain, review_chain], \n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(overall_chain(\"朝の通勤でほっこりしたこと\"))"
      ],
      "metadata": {
        "id": "Hbfp5KHGqAt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SequentialChainの例（こちらの方が多分使いやすい）"
      ],
      "metadata": {
        "id": "hT8ctD-Ory1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1つ目のチェーン : 劇のタイトルと時代からあらすじを生成\n",
        "\n",
        "# LLMの準備\n",
        "llm = OpenAI(temperature=.7)\n",
        "\n",
        "# テンプレートの準備\n",
        "# テンプレートの準備\n",
        "template = \"\"\"あなたは劇作家です。劇のタイトルと時代が与えられた場合、そのタイトルのあらすじを書くのがあなたの仕事です。\n",
        "\n",
        "タイトル:{title}\n",
        "時代:{era}\n",
        "あらすじ:\"\"\"\n",
        "\n",
        "# プロンプトテンプレートの生成\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"title\", 'era'], \n",
        "    template=template\n",
        ")\n",
        "\n",
        "# LLMChainの準備\n",
        "synopsis_chain = LLMChain(\n",
        "    llm=llm, \n",
        "    prompt=prompt_template, \n",
        "    output_key=\"synopsis\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 2つ目のチェーン : 劇のあらすじからレビューを生成\n",
        "\n",
        "# LLMの準備準備\n",
        "llm = OpenAI(temperature=.7)\n",
        "\n",
        "# テンプレートの準備\n",
        "template = \"\"\"あなたは演劇評論家です。 劇のあらすじが与えられた場合、そのあらすじのレビューを書くのがあなたの仕事です。\n",
        "\n",
        "あらすじ:\n",
        "{synopsis}\n",
        "レビュー:\"\"\"\n",
        "\n",
        "# プロンプトテンプレートの準備\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"synopsis\"], \n",
        "    template=template\n",
        ")\n",
        "\n",
        "# LLMChainの準備\n",
        "review_chain = LLMChain(\n",
        "    llm=llm, prompt=prompt_template, \n",
        "    output_key=\"review\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "from langchain.chains import SequentialChain\n",
        "\n",
        "# SequentialChainで2つのチェーンを繋ぐ\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[synopsis_chain, review_chain],\n",
        "    input_variables=[\"era\", \"title\"],\n",
        "    output_variables=[\"synopsis\", \"review\"],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "DfLDVLEwsBQG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SequentialChainの実行\n",
        "review = overall_chain({\"title\":\"通勤時にほっこりしたこと\", \"era\": \"戦国時代\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6wciuJ_sXb-",
        "outputId": "4520de34-728a-43b9-84d0-e8a9264f9c23"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"あらすじ：{review['synopsis']}\")\n",
        "print(\"\")\n",
        "print(f\"評論：{review['review']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rolKqaPZtTF2",
        "outputId": "14094781-7739-44f4-a313-d86a943c0c23"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "あらすじ：\n",
            "\n",
            "戦国時代の朝、ある農家の娘と彼女の叔父が、彼女を大都市に連れて行く旅をしていました。彼女は驚いて、そこで何が起こるのか想像できませんでした。着いた先は、大きな城が立ち並ぶ大都市でした。そして娘は彼女の叔父と同じように、農場から大都市への旅を毎朝、通勤する農民の姿を見ていました。農民たちは行動することで、自分の夢を叶えようとしていました。そして、\n",
            "\n",
            "評論：\n",
            "\n",
            "この作品は、戦国時代の農家の娘が、叔父と一緒に大都市への旅をし、そこで何が起きるのかを想像できない状況にあるという物語です。この作品の主人公は、農民たちが毎朝行動を起こして、自分の夢を叶えようとしている姿を見て、勇気を得ることができます。作品全体は、戦国時代の大都市の生活を熱望する農民たちの姿を描写しています。この作品は、勇気を持って夢を\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agents\n",
        "\n",
        "Chainをどのような順番で動かすかを決定する\n",
        "\n",
        "・zero-shot-react-description：  Toolのdescription（説明文）をもとに、どのToolを選択するか決定する\n",
        "\n",
        "・react-docstore:  ドキュメントを検索するSearchと、検索結果から用語を探すLookupという2つのToolを用意\n",
        "\n",
        "・self-ask-with-search:  Google検索等を用いて、自問自答・検索を繰り返しながら答えを導く\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5wOEG9hraXZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import LLMMathChain, SerpAPIWrapper\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "search = SerpAPIWrapper()\n",
        "llm_math_chain = LLMMathChain(llm=llm, verbose=True)\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about current events\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=llm_math_chain.run,\n",
        "        description=\"useful for when you need to answer questions about math\"\n",
        "    )\n",
        "]\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "agent.run(\"日本で一番高い山の高さは何メートルですか?その高さの5乗根を求めてください。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "id": "0xn9d4mCbLTJ",
        "outputId": "63a855b8-8730-430a-849e-e10b31712e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find the height of the highest mountain in Japan and then calculate its fifth root.\n",
            "Action: Search\n",
            "Action Input: \"highest mountain in Japan\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mMount Fuji\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find the height of Mount Fuji\n",
            "Action: Search\n",
            "Action Input: \"height of Mount Fuji\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m12,388′\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to convert this to meters\n",
            "Action: Calculator\n",
            "Action Input: 12,388 * 0.3048\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "12,388 * 0.3048\u001b[32;1m\u001b[1;3m\n",
            "Answer: 3760.544\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3760.544\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the fifth root of 3760.544\n",
            "Action: Calculator\n",
            "Action Input: 3760.544^(1/5)\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "3760.544^(1/5)\u001b[32;1m\u001b[1;3m\n",
            "```python\n",
            "print(3760.544**(1/5))\n",
            "```\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m5.188599325914775\n",
            "\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 5.188599325914775\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The height of the highest mountain in Japan is 3760.544 meters and its fifth root is 5.188599325914775.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The height of the highest mountain in Japan is 3760.544 meters and its fifth root is 5.188599325914775.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory\n",
        "\n",
        "前までの会話を覚えておく\n",
        "\n",
        "・  ConversationBufferMemory  前段までの入力・出力をそのまま記憶する\n",
        "\n",
        "・  ConversationalBufferWindowMemory  k段前までの入力・出力をそのまま記憶する\n",
        "\n",
        "・  ConversationSummaryMemory  前段までの入力・出力をLLMでサマライズして記憶する"
      ],
      "metadata": {
        "id": "yDlM89GFcodW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Google custom searchを併用する**\n",
        "\n",
        "https://note.com/npaka/n/nd9a4a26a8932"
      ],
      "metadata": {
        "id": "KvvPSSpliGGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor, load_tools\n",
        "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
        "\n",
        "# ツールの準備\n",
        "tools = load_tools([\"google-search\"], llm=OpenAI())"
      ],
      "metadata": {
        "id": "IrZazoRqiKe8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#テンプレートの準備\n",
        "prefix = \"\"\"次の質問にできる限り答えてください。次のツールにアクセスできます:\"\"\"\n",
        "suffix = \"\"\"始めましょう! 最終的な答えを出すときは、一人称は\"ぼく\"、語尾には\"なのだ\"を使用してください\n",
        "\n",
        "Question: {input}\n",
        "{agent_scratchpad}\"\"\"\n",
        "\n",
        "prompt = ZeroShotAgent.create_prompt(\n",
        "    tools,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"input\", \"agent_scratchpad\"]\n",
        ")\n",
        "\n",
        "# エージェントの準備\n",
        "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
        "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools)\n",
        "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "0iugockNiYZr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.run(\"天才バカボンのパパが卒業した大学は？\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "AYl3Hb4rick7",
        "outputId": "54c218ab-6477-4aa5-a9fa-315889a53ba6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: パパの卒業大学を探す\n",
            "Action: Google Search\n",
            "Action Input: 天才バカボン パパ 卒業大学\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mJul 31, 2018 ... バカボンのパパが「バカ田大学」を卒業（哲学科の首席！）したことは有名な話ですが、その在学中には「黒百合女学院」の“マドンナ”（のちのママ）に恋 ... バカボンのパパ（バカボンパパ）は、赤塚不二夫のギャグ漫画・『天才バカボン』、ならびにそれを ... 最終学歴, バカ田大学 ... 天才バカボン』を第5作と記す。 天才バカボン キャラ紹介. パパバカ田大学を主席で卒業するも、定職に就かず「これでいいのだ！ ... 時に、パパを懸命に怒っている姿さえも愛らしい。 バカ田大学とは赤塚不二夫のギャグ漫画「天才バカボン」に登場する大学。バカボンのパパを輩出したことで有名。 概要 バカ田大学とは赤塚不二夫のギャグ漫画「天才 ... 天才バカボンのパパは、熊本県に実在する菊地市立七城中学校から東京都のバカ田高校を経て、バカ田大学を主席で卒業。かなり多くの職を転々としていますが、店舗を全焼 ... バカ田大学社会学部哲学科出身です。東京の西北早稲田の隣です。生徒の中にはアホウドリもいます。 姉妹校には「アッホー大学」、「バーカード大学」があります。 Sep 11, 2008 ... 天才バカボンの大神秘―バカボンのパパの知能指数は12500なのだ!?作者: バカ田大学後援会出版社/メーカー: ベストセラーズ発売日: 1993/06メディア: ... 名称は早稲田大学のパロディであり、校歌の歌詞もモデルの「都の西北早稲田の森に～」をもじり、「都の東北早稲田の隣～」となっている。バカボンのパパが首席で卒業した ... バカボンのパパは、熊本県金地郡七城町立七城中学校、東京都のバカ田高校を経てバカ田大学を首席で卒業。学級委員も務めています。/ バカボンのパパ（バカボンパパ）は、赤塚不二夫のギャグ漫画・『天才 ... バカ田大学の卒業式の日、「東洋工業（現・マツダ）に入社してマツダ・キャロルを作るのだ」 ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m パパが卒業した大学はバカ田大学なのだ\n",
            "Final Answer: パパはバカ田大学を首席で卒業したなのだ。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'パパはバカ田大学を首席で卒業したなのだ。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 危ないアドレスかどうかを判断する\n",
        "\n",
        "※これはColabでは動きません...\n",
        "\n",
        "https://zenn.dev/tatsui/articles/c4b4f796a85395"
      ],
      "metadata": {
        "id": "rDAqFsqhjFec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import click\n",
        "\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain import OpenAI, SerpAPIWrapper, LLMChain, LLMMathChain, LLMBashChain\n",
        "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor, load_tools, initialize_agent\n",
        "\n",
        "def generate_prompt(identifier:str,input_value:str):\n",
        "    if identifier in [\"url\", \"domain\"]:\n",
        "        prompt = f\"\"\"\n",
        "以下の手順を使ってURL({input_value})の調査を行い、悪意の有無について「日本語」で出力してください。\n",
        "* digコマンドを使って入力されたドメイン名からIPアドレスを取得します。\n",
        "* whoisコマンドを使ってWhois情報を取得します。\n",
        "* IPアドレスをgoogleで検索する\n",
        "\n",
        "判定基準\n",
        "* IP Abuse Reports\n",
        "\"\"\"\n",
        "\n",
        "    if identifier == \"ip\":\n",
        "        prompt = f\"\"\"\n",
        "以下の手順を使ってIPアドレス({input_value})の調査を行い、悪意の有無について「日本語」で出力してください。\n",
        "* whoisコマンドを使ってWhois情報を取得します。\n",
        "* IPアドレスをgoogleで検索する\n",
        "\n",
        "判定基準\n",
        "* 悪意のあるIPアドレスとして報告されている\n",
        "* IP Abuse Reports\n",
        "\"\"\"\n",
        "\n",
        "    if identifier == \"hash\":\n",
        "       prompt = f\"\"\"\n",
        "以下の手順を使ってHash({input_value})の調査を行い、悪意の有無について「日本語」で出力してください。\n",
        "* ハッシュ値をGoogle検索する\n",
        "\n",
        "判定基準\n",
        "* 悪意のあるファイルとして報告されている\n",
        "\"\"\"\n",
        "    return prompt\n",
        "\n",
        "@click.command()\n",
        "@click.option(\"--url\", \"identifier\", flag_value=\"url\", help=\"Investigate based on URL.\")\n",
        "@click.option(\"--hash\", \"identifier\", flag_value=\"hash\", help=\"Investigate based on file hash.\")\n",
        "@click.option(\"--domain\", \"identifier\", flag_value=\"domain\", help=\"Investigate based on domain name.\")\n",
        "@click.option(\"--ip\", \"identifier\", flag_value=\"ip\", help=\"Investigate based on IP address.\")\n",
        "@click.argument(\"input_value\")\n",
        "def main(identifier: str, input_value: str):\n",
        "    # ツールの準備\n",
        "    llm = OpenAI(temperature=0)\n",
        "    tools = load_tools([\"terminal\", \"google-search\"], llm=llm)\n",
        "    llm_math_chain = LLMMathChain(llm=llm, verbose=True)\n",
        "    llm_bash_chain = LLMBashChain(llm=llm, verbose=True)\n",
        "    tools.append(\n",
        "        Tool(\n",
        "            name=\"Calculator\",\n",
        "            func=llm_math_chain.run,\n",
        "            description=\"useful for when you need to answer questions about math\",\n",
        "        )\n",
        "    )\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "    prompt = generate_prompt(identifier, input_value)\n",
        "    agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
        "    agent.run(prompt)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "854EqcbejH3J",
        "outputId": "ba414788-4c08-40d9-aee6-c4f32ec00122"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Usage: ipykernel_launcher.py [OPTIONS] INPUT_VALUE\n",
            "Try 'ipykernel_launcher.py --help' for help.\n",
            "\n",
            "Error: no such option: -f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**AI chatbot**\n",
        "\n",
        "https://qiita.com/hideki/items/b26154ab503fd3394a0b"
      ],
      "metadata": {
        "id": "MzryN14JktCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain --q\n",
        "!pip install openai --q\n",
        "!pip install gradio --q"
      ],
      "metadata": {
        "id": "kFSaw2kNkvUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "from langchain import OpenAI, ConversationChain\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = key[3]\n",
        "\n",
        "llm = OpenAI(temperature=0.95)\n",
        "conversation = ConversationChain(llm=llm, verbose=False)\n",
        "\n",
        "\n",
        "def chat(message, history):\n",
        "    history = history or []\n",
        "    response = conversation.predict(input=message)\n",
        "    history.append((message, response))\n",
        "\n",
        "    return history, history\n",
        "\n",
        "\n",
        "chatbot = gr.Chatbot().style(color_map=('green', 'pink'))\n",
        "demo = gr.Interface(\n",
        "    chat,\n",
        "    ['text', 'state'],\n",
        "    [chatbot, 'state'],\n",
        "    allow_flagging='never',\n",
        ")\n",
        "if __name__ == '__main__':\n",
        "    demo.launch()"
      ],
      "metadata": {
        "id": "wcv2bqzykzPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### コードエンジニアリングをしてみる"
      ],
      "metadata": {
        "id": "BOCT2Vj1mCWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "from langchain import OpenAI, ConversationChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = key[3]\n",
        "\n",
        "llm = OpenAI(temperature=1)\n",
        "conversation = ConversationChain(llm=llm, verbose=False)\n",
        "\n",
        "template = '''I need you to act as a research assistant for a scientific article I am writing. I will provide you with specific questions and information, and I expect you to find relevant and credible sources to support my research. Your responses should include a summary of the main points from the sources, along with the full citation in the desired format (APA, MLA, etc.). Additionally, you should flag any potential issues or limitations in the sources you provide. The title of the article is: Real-time smartphone identification of corneal diseases displayed on computer screen  using embedded deep-learning model: a validation study\n",
        "\n",
        "{history}\n",
        "{input}\n",
        "'''\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['history', 'input'],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    verbose=True)\n",
        "\n",
        "\n",
        "def chat(message, history):\n",
        "    history = history or []\n",
        "    response = conversation.predict(input=message)\n",
        "    history.append((message, response))\n",
        "\n",
        "    return history, history\n",
        "\n",
        "\n",
        "chatbot = gr.Chatbot().style(color_map=('green', 'pink'))\n",
        "demo = gr.Interface(\n",
        "    chat,\n",
        "    ['text', 'state'],\n",
        "    [chatbot, 'state'],\n",
        "    allow_flagging='never',\n",
        ")\n",
        "if __name__ == '__main__':\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "sRGf-3m-luV7",
        "outputId": "7c10c6a7-e205-4f8d-a3bb-d553e1cb3765"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7863, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}